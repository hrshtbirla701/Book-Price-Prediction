{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "import warnings\n",
    "from datetime import date\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6237, 9) (1560, 8)\n"
     ]
    }
   ],
   "source": [
    "# train = pd.read_excel(\"Data/Data_Train.xlsx\")\n",
    "# test = pd.read_excel(\"Data/Data_Test.xlsx\")\n",
    "train = pd.read_excel('Data_Train.xlsx')\n",
    "test = pd.read_excel('Data_Test.xlsx')\n",
    "#date.today().strftime('%d %b %Y')\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Edition</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Genre</th>\n",
       "      <th>BookCategory</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Prisoner's Gold (The Hunters 3)</td>\n",
       "      <td>Chris Kuzneski</td>\n",
       "      <td>Paperback,– 10 Mar 2016</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>8 customer reviews</td>\n",
       "      <td>THE HUNTERS return in their third brilliant no...</td>\n",
       "      <td>Action &amp; Adventure (Books)</td>\n",
       "      <td>Action &amp; Adventure</td>\n",
       "      <td>220.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guru Dutt: A Tragedy in Three Acts</td>\n",
       "      <td>Arun Khopkar</td>\n",
       "      <td>Paperback,– 7 Nov 2012</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>14 customer reviews</td>\n",
       "      <td>A layered portrait of a troubled genius for wh...</td>\n",
       "      <td>Cinema &amp; Broadcast (Books)</td>\n",
       "      <td>Biographies, Diaries &amp; True Accounts</td>\n",
       "      <td>202.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leviathan (Penguin Classics)</td>\n",
       "      <td>Thomas Hobbes</td>\n",
       "      <td>Paperback,– 25 Feb 1982</td>\n",
       "      <td>4.8 out of 5 stars</td>\n",
       "      <td>6 customer reviews</td>\n",
       "      <td>\"During the time men live without a common Pow...</td>\n",
       "      <td>International Relations</td>\n",
       "      <td>Humour</td>\n",
       "      <td>299.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Pocket Full of Rye (Miss Marple)</td>\n",
       "      <td>Agatha Christie</td>\n",
       "      <td>Paperback,– 5 Oct 2017</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>13 customer reviews</td>\n",
       "      <td>A handful of grain is found in the pocket of a...</td>\n",
       "      <td>Contemporary Fiction (Books)</td>\n",
       "      <td>Crime, Thriller &amp; Mystery</td>\n",
       "      <td>180.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIFE 70 Years of Extraordinary Photography</td>\n",
       "      <td>Editors of Life</td>\n",
       "      <td>Hardcover,– 10 Oct 2006</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>1 customer review</td>\n",
       "      <td>For seven decades, \"Life\" has been thrilling t...</td>\n",
       "      <td>Photography Textbooks</td>\n",
       "      <td>Arts, Film &amp; Photography</td>\n",
       "      <td>965.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Title           Author  \\\n",
       "0         The Prisoner's Gold (The Hunters 3)   Chris Kuzneski   \n",
       "1          Guru Dutt: A Tragedy in Three Acts     Arun Khopkar   \n",
       "2                Leviathan (Penguin Classics)    Thomas Hobbes   \n",
       "3          A Pocket Full of Rye (Miss Marple)  Agatha Christie   \n",
       "4  LIFE 70 Years of Extraordinary Photography  Editors of Life   \n",
       "\n",
       "                   Edition             Reviews              Ratings  \\\n",
       "0  Paperback,– 10 Mar 2016  4.0 out of 5 stars   8 customer reviews   \n",
       "1   Paperback,– 7 Nov 2012  3.9 out of 5 stars  14 customer reviews   \n",
       "2  Paperback,– 25 Feb 1982  4.8 out of 5 stars   6 customer reviews   \n",
       "3   Paperback,– 5 Oct 2017  4.1 out of 5 stars  13 customer reviews   \n",
       "4  Hardcover,– 10 Oct 2006  5.0 out of 5 stars    1 customer review   \n",
       "\n",
       "                                            Synopsis  \\\n",
       "0  THE HUNTERS return in their third brilliant no...   \n",
       "1  A layered portrait of a troubled genius for wh...   \n",
       "2  \"During the time men live without a common Pow...   \n",
       "3  A handful of grain is found in the pocket of a...   \n",
       "4  For seven decades, \"Life\" has been thrilling t...   \n",
       "\n",
       "                          Genre                          BookCategory   Price  \n",
       "0    Action & Adventure (Books)                    Action & Adventure  220.00  \n",
       "1    Cinema & Broadcast (Books)  Biographies, Diaries & True Accounts  202.93  \n",
       "2       International Relations                                Humour  299.00  \n",
       "3  Contemporary Fiction (Books)             Crime, Thriller & Mystery  180.00  \n",
       "4         Photography Textbooks              Arts, Film & Photography  965.62  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6237 entries, 0 to 6236\n",
      "Data columns (total 9 columns):\n",
      "Title           6237 non-null object\n",
      "Author          6237 non-null object\n",
      "Edition         6237 non-null object\n",
      "Reviews         6237 non-null object\n",
      "Ratings         6237 non-null object\n",
      "Synopsis        6237 non-null object\n",
      "Genre           6237 non-null object\n",
      "BookCategory    6237 non-null object\n",
      "Price           6237 non-null float64\n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 438.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Edition</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Genre</th>\n",
       "      <th>BookCategory</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5568</td>\n",
       "      <td>3679</td>\n",
       "      <td>3370</td>\n",
       "      <td>36</td>\n",
       "      <td>342</td>\n",
       "      <td>5549</td>\n",
       "      <td>345</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Title Author Edition Reviews Ratings Synopsis Genre BookCategory  \\\n",
       "count   6237   6237    6237    6237    6237     6237  6237         6237   \n",
       "unique  5568   3679    3370      36     342     5549   345           11   \n",
       "\n",
       "         Price  \n",
       "count   6237.0  \n",
       "unique     NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe(include = 'all').head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'Author', 'Edition', 'Reviews', 'Ratings', 'Synopsis', 'Genre',\n",
       "       'BookCategory', 'Price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['Title', 'Author', 'Edition', 'Reviews', 'Ratings','Genre',\n",
    "               'BookCategory', 'Price']]\n",
    "\n",
    "test = test[['Title', 'Author', 'Edition', 'Reviews', 'Ratings','Genre',\n",
    "               'BookCategory']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title           0\n",
       "Author          0\n",
       "Edition         0\n",
       "Reviews         0\n",
       "Ratings         0\n",
       "Genre           0\n",
       "BookCategory    0\n",
       "Price           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_edition(data):  \n",
    "  \n",
    "  edition  = list(data)\n",
    "  \n",
    "  ed_type = [i.split(\",– \")[0].strip().upper() for i in edition]\n",
    "  \n",
    "  edit_date = [i.split(\",– \")[1].strip() for i in edition]\n",
    "  \n",
    "  m_y = [i.split()[-2:] for i in edit_date]\n",
    "  \n",
    "  \n",
    "  for i in range(len(m_y)):\n",
    "    if len(m_y[i]) == 1:\n",
    "      m_y[i].insert(0,'NA')\n",
    "      \n",
    "  # Based on the given dataset below is the list of possible values for Months\n",
    "  \n",
    "  months =  ['Apr','Aug','Dec','Feb', 'Jan', 'Jul','Jun','Mar','May','NA','Nov','Oct','Sep']\n",
    "  \n",
    "  ed_month = [m_y[i][0].upper() if m_y[i][0] in months else 'NA' for i in range(len(m_y))]\n",
    "  ed_year = [int(m_y[i][1].strip()) if m_y[i][1].isdigit() else 0 for i in range(len(m_y))]\n",
    "  \n",
    "  return ed_type, ed_month, ed_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max. number of authors for a single boook =  7\n",
      "7008\n"
     ]
    }
   ],
   "source": [
    "#Identifying the maximum number of authors for a single book from the given datasets\n",
    "authors_1 = list(train['Author'])\n",
    "authors_2 = list(test['Author'])\n",
    "\n",
    "authors_1.extend(authors_2)\n",
    "\n",
    "authorslis = [i.split(\",\") for i in authors_1]\n",
    "\n",
    "max = 1\n",
    "for i in authorslis:\n",
    "  if len(i) >= max:\n",
    "    max = len(i)\n",
    "print(\"Max. number of authors for a single boook = \",max)\n",
    "\n",
    "for i in range(len(authorslis)):\n",
    "  if len(authorslis[i]) == max:\n",
    "    print(i)    \n",
    "    \n",
    "all_authors = [author.strip().upper() for listin in authorslis for author in listin]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A method to split the Author column in to 7 new columns\n",
    "def split_authors(data):\n",
    "  \n",
    "  authors = list(data)\n",
    "  \n",
    "  A1 = []\n",
    "  A2 = []\n",
    "  A3 = []\n",
    "  A4 = []\n",
    "  A5 = []\n",
    "  A6 = []\n",
    "  A7 = []\n",
    "  for i in authors:\n",
    "    \n",
    "    try :\n",
    "      A1.append(i.split(',')[0].strip().upper())\n",
    "    except :\n",
    "      A1.append('NONE')\n",
    "      \n",
    "    try :\n",
    "      A2.append(i.split(',')[1].strip().upper())\n",
    "    except :\n",
    "      A2.append('NONE')\n",
    "        \n",
    "    try :\n",
    "      A3.append(i.split(',')[2].strip().upper())\n",
    "    except :\n",
    "      A3.append('NONE')\n",
    "        \n",
    "    try :\n",
    "      A4.append(i.split(',')[3].strip().upper())\n",
    "    except :\n",
    "      A4.append('NONE')\n",
    "        \n",
    "    try :\n",
    "      A5.append(i.split(',')[4].strip().upper())\n",
    "    except :\n",
    "      A5.append('NONE')\n",
    "      \n",
    "    try :\n",
    "      A6.append(i.split(',')[5].strip().upper())\n",
    "    except :\n",
    "      A6.append('NONE')\n",
    "     \n",
    "    try :\n",
    "      A7.append(i.split(',')[6].strip().upper())\n",
    "    except :\n",
    "      A7.append('NONE')\n",
    "\n",
    "      \n",
    "  return A1,A2,A3,A4,A5,A6,A7\n",
    "  \n",
    "all_authors.append('NONE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max. number of genres for a single boook =  2\n"
     ]
    }
   ],
   "source": [
    "#Identifying the maximum number of Genres for a single book from the given datasets\n",
    "\n",
    "genre_1 = list(train['Genre'])\n",
    "genre_2 = list(test['Genre'])\n",
    "\n",
    "genre_1.extend(genre_2)\n",
    "\n",
    "genre_lis = [i.split(\",\") for i in genre_1]\n",
    "\n",
    "\n",
    "max = 1\n",
    "for i in genre_lis:\n",
    "  if len(i) >= max:\n",
    "    max = len(i)\n",
    "print(\"Max. number of genres for a single boook = \",max)\n",
    "      \n",
    "all_genres = [genre.strip().upper() for listin in genre_lis for genre in listin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A method to split the Genre column in to 2 new columns\n",
    "\n",
    "def split_genres(data):\n",
    "  \n",
    "  genres = list(data)\n",
    "  \n",
    "  G1 = []\n",
    "  G2 = []\n",
    "  \n",
    "  for i in genres:\n",
    "    \n",
    "    try :\n",
    "      G1.append(i.split(',')[0].strip().upper())\n",
    "      \n",
    "    except :\n",
    "      G1.append('NONE')\n",
    "      \n",
    "    try :\n",
    "      G2.append(i.split(',')[1].strip().upper())\n",
    "    except :\n",
    "      G2.append('NONE')\n",
    "\n",
    "\n",
    "      \n",
    "  return G1,G2\n",
    "  \n",
    "all_genres.append('NONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max. number of Categories for a single boook =  2\n"
     ]
    }
   ],
   "source": [
    "#Identifying the maximum number of Categories for a single book from the given datasets\n",
    "\n",
    "cat_1 = list(train['BookCategory'])\n",
    "cat_2 = list(test['BookCategory'])\n",
    "\n",
    "cat_1.extend(cat_2)\n",
    "\n",
    "cat_lis = [i.split(\",\") for i in cat_1]\n",
    "\n",
    "\n",
    "max = 1\n",
    "for i in cat_lis:\n",
    "  if len(i) >= max:\n",
    "    max = len(i)\n",
    "print(\"Max. number of Categories for a single boook = \",max)\n",
    "\n",
    "all_categories = [cat.strip().upper() for listin in cat_lis for cat in listin]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A method to split the Category column in to 7 new columns\n",
    "\n",
    "def split_categories(data):\n",
    "  \n",
    "  cat = list(data)\n",
    "  \n",
    "  C1 = []\n",
    "  C2 = []\n",
    "\n",
    "  for i in cat:\n",
    "    \n",
    "    try :\n",
    "      C1.append(i.split(',')[0].strip().upper())\n",
    "    except :\n",
    "      C1.append('NONE')\n",
    "      \n",
    "    try :\n",
    "      C2.append(i.split(',')[1].strip().upper())\n",
    "    except :\n",
    "      C2.append('NONE')\n",
    "\n",
    "\n",
    "      \n",
    "  return C1,C2\n",
    "  \n",
    "all_categories.append('NONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A method to clean and restructure the datasets\n",
    "\n",
    "import re\n",
    "\n",
    "def restructure(data):\n",
    "  \n",
    "  #Cleaning Title Column\n",
    "  titles = list(data['Title'])\n",
    "  titles = [title.strip().upper() for title in titles]\n",
    "  \n",
    "  #Cleaning & Restructuring Author Column\n",
    "  a1,a2,a3,a4,a5,a6,a7 = split_authors(data['Author']) \n",
    "  \n",
    "  #Cleaning & Restructuring Edition Column\n",
    "  ed_type, ed_month, ed_year = split_edition(data['Edition'])\n",
    "  \n",
    "  #Cleaning Ratings Column\n",
    "  ratings = list(data['Reviews'])\n",
    "  ratings = [float(re.sub(\" out of 5 stars\", \"\", i).strip()) for i in ratings]\n",
    "  \n",
    "  #Cleaning Reviews Column\n",
    "  reviews = list(data['Ratings'])\n",
    "  plu = ' customer reviews'\n",
    "  reviews = [re.sub(\" customer reviews\", \"\", i) if plu in i else re.sub(\" customer review\", \"\", i) for i in reviews  ]\n",
    "  reviews = [int(re.sub(\",\", \"\", i).strip()) for i in reviews ]\n",
    "  \n",
    "\n",
    "  #Cleaning & Restructuring Genre Column\n",
    "  g1, g2 = split_genres(data['Genre'])\n",
    "  \n",
    "  #Cleaning & Restructuring BookCategory Column\n",
    "  c1,c2 = split_categories(data['BookCategory'])\n",
    "\n",
    "  # Forming the Structured dataset\n",
    "  structured_data = pd.DataFrame({'Title': titles,\n",
    "                                  'Author1': a1,\n",
    "                                  'Author2': a2,\n",
    "                                  'Author3': a3,\n",
    "                                  'Author4': a4,\n",
    "                                  'Author5': a5,\n",
    "                                  'Author6': a6,\n",
    "                                  'Author7': a7,\n",
    "                                  'Edition_Type': ed_type,\n",
    "                                  'Edition_Month': ed_month,\n",
    "                                  'Edition_Year': ed_year,\n",
    "                                  'Ratings': ratings,\n",
    "                                  'Reviews': reviews,\n",
    "                                  'Genre1': g1,\n",
    "                                  'Genre2': g2,\n",
    "                                  'Category1': c1,\n",
    "                                  'Category2': c2\n",
    "                                  \n",
    "                               })\n",
    "  \n",
    "  return structured_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author1</th>\n",
       "      <th>Author2</th>\n",
       "      <th>Author3</th>\n",
       "      <th>Author4</th>\n",
       "      <th>Author5</th>\n",
       "      <th>Author6</th>\n",
       "      <th>Author7</th>\n",
       "      <th>Edition_Type</th>\n",
       "      <th>Edition_Month</th>\n",
       "      <th>Edition_Year</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Genre1</th>\n",
       "      <th>Genre2</th>\n",
       "      <th>Category1</th>\n",
       "      <th>Category2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE PRISONER'S GOLD (THE HUNTERS 3)</td>\n",
       "      <td>CHRIS KUZNESKI</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>PAPERBACK</td>\n",
       "      <td>MAR</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>ACTION &amp; ADVENTURE (BOOKS)</td>\n",
       "      <td>NONE</td>\n",
       "      <td>ACTION &amp; ADVENTURE</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GURU DUTT: A TRAGEDY IN THREE ACTS</td>\n",
       "      <td>ARUN KHOPKAR</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>PAPERBACK</td>\n",
       "      <td>NOV</td>\n",
       "      <td>2012</td>\n",
       "      <td>3.9</td>\n",
       "      <td>14</td>\n",
       "      <td>CINEMA &amp; BROADCAST (BOOKS)</td>\n",
       "      <td>NONE</td>\n",
       "      <td>BIOGRAPHIES</td>\n",
       "      <td>DIARIES &amp; TRUE ACCOUNTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LEVIATHAN (PENGUIN CLASSICS)</td>\n",
       "      <td>THOMAS HOBBES</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>PAPERBACK</td>\n",
       "      <td>FEB</td>\n",
       "      <td>1982</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6</td>\n",
       "      <td>INTERNATIONAL RELATIONS</td>\n",
       "      <td>NONE</td>\n",
       "      <td>HUMOUR</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title         Author1 Author2 Author3  \\\n",
       "0  THE PRISONER'S GOLD (THE HUNTERS 3)  CHRIS KUZNESKI    NONE    NONE   \n",
       "1   GURU DUTT: A TRAGEDY IN THREE ACTS    ARUN KHOPKAR    NONE    NONE   \n",
       "2         LEVIATHAN (PENGUIN CLASSICS)   THOMAS HOBBES    NONE    NONE   \n",
       "\n",
       "  Author4 Author5 Author6 Author7 Edition_Type Edition_Month  Edition_Year  \\\n",
       "0    NONE    NONE    NONE    NONE    PAPERBACK           MAR          2016   \n",
       "1    NONE    NONE    NONE    NONE    PAPERBACK           NOV          2012   \n",
       "2    NONE    NONE    NONE    NONE    PAPERBACK           FEB          1982   \n",
       "\n",
       "   Ratings  Reviews                      Genre1 Genre2           Category1  \\\n",
       "0      4.0        8  ACTION & ADVENTURE (BOOKS)   NONE  ACTION & ADVENTURE   \n",
       "1      3.9       14  CINEMA & BROADCAST (BOOKS)   NONE         BIOGRAPHIES   \n",
       "2      4.8        6     INTERNATIONAL RELATIONS   NONE              HUMOUR   \n",
       "\n",
       "                 Category2  \n",
       "0                     NONE  \n",
       "1  DIARIES & TRUE ACCOUNTS  \n",
       "2                     NONE  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restructure(train).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = restructure(train)\n",
    "\n",
    "Y_train = train.iloc[:, -1].values\n",
    "\n",
    "X_test = restructure(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author1</th>\n",
       "      <th>Author2</th>\n",
       "      <th>Author3</th>\n",
       "      <th>Author4</th>\n",
       "      <th>Author5</th>\n",
       "      <th>Author6</th>\n",
       "      <th>Author7</th>\n",
       "      <th>Edition_Type</th>\n",
       "      <th>Edition_Month</th>\n",
       "      <th>Edition_Year</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Genre1</th>\n",
       "      <th>Genre2</th>\n",
       "      <th>Category1</th>\n",
       "      <th>Category2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237.000000</td>\n",
       "      <td>6237.000000</td>\n",
       "      <td>6237.000000</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5564</td>\n",
       "      <td>3633</td>\n",
       "      <td>264</td>\n",
       "      <td>73</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>345</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>CASINO ROYALE: JAMES BOND 007 (VINTAGE)</td>\n",
       "      <td>AGATHA CHRISTIE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>PAPERBACK</td>\n",
       "      <td>OCT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACTION &amp; ADVENTURE (BOOKS)</td>\n",
       "      <td>NONE</td>\n",
       "      <td>ACTION &amp; ADVENTURE</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "      <td>5929</td>\n",
       "      <td>6159</td>\n",
       "      <td>6214</td>\n",
       "      <td>6233</td>\n",
       "      <td>6237</td>\n",
       "      <td>6237</td>\n",
       "      <td>5193</td>\n",
       "      <td>639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>947</td>\n",
       "      <td>5594</td>\n",
       "      <td>818</td>\n",
       "      <td>3297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005.101972</td>\n",
       "      <td>4.293202</td>\n",
       "      <td>35.984287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.821510</td>\n",
       "      <td>0.662501</td>\n",
       "      <td>149.995031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6090.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title          Author1 Author2  \\\n",
       "count                                      6237             6237    6237   \n",
       "unique                                     5564             3633     264   \n",
       "top     CASINO ROYALE: JAMES BOND 007 (VINTAGE)  AGATHA CHRISTIE    NONE   \n",
       "freq                                          4               69    5929   \n",
       "mean                                        NaN              NaN     NaN   \n",
       "std                                         NaN              NaN     NaN   \n",
       "min                                         NaN              NaN     NaN   \n",
       "25%                                         NaN              NaN     NaN   \n",
       "50%                                         NaN              NaN     NaN   \n",
       "75%                                         NaN              NaN     NaN   \n",
       "max                                         NaN              NaN     NaN   \n",
       "\n",
       "       Author3 Author4 Author5 Author6 Author7 Edition_Type Edition_Month  \\\n",
       "count     6237    6237    6237    6237    6237         6237          6237   \n",
       "unique      73      21       5       1       1           19            13   \n",
       "top       NONE    NONE    NONE    NONE    NONE    PAPERBACK           OCT   \n",
       "freq      6159    6214    6233    6237    6237         5193           639   \n",
       "mean       NaN     NaN     NaN     NaN     NaN          NaN           NaN   \n",
       "std        NaN     NaN     NaN     NaN     NaN          NaN           NaN   \n",
       "min        NaN     NaN     NaN     NaN     NaN          NaN           NaN   \n",
       "25%        NaN     NaN     NaN     NaN     NaN          NaN           NaN   \n",
       "50%        NaN     NaN     NaN     NaN     NaN          NaN           NaN   \n",
       "75%        NaN     NaN     NaN     NaN     NaN          NaN           NaN   \n",
       "max        NaN     NaN     NaN     NaN     NaN          NaN           NaN   \n",
       "\n",
       "        Edition_Year      Ratings      Reviews                      Genre1  \\\n",
       "count    6237.000000  6237.000000  6237.000000                        6237   \n",
       "unique           NaN          NaN          NaN                         345   \n",
       "top              NaN          NaN          NaN  ACTION & ADVENTURE (BOOKS)   \n",
       "freq             NaN          NaN          NaN                         947   \n",
       "mean     2005.101972     4.293202    35.984287                         NaN   \n",
       "std       116.821510     0.662501   149.995031                         NaN   \n",
       "min         0.000000     1.000000     1.000000                         NaN   \n",
       "25%      2010.000000     4.000000     2.000000                         NaN   \n",
       "50%      2014.000000     4.400000     7.000000                         NaN   \n",
       "75%      2017.000000     4.800000    22.000000                         NaN   \n",
       "max      2019.000000     5.000000  6090.000000                         NaN   \n",
       "\n",
       "       Genre2           Category1 Category2  \n",
       "count    6237                6237      6237  \n",
       "unique     27                  11         6  \n",
       "top      NONE  ACTION & ADVENTURE      NONE  \n",
       "freq     5594                 818      3297  \n",
       "mean      NaN                 NaN       NaN  \n",
       "std       NaN                 NaN       NaN  \n",
       "min       NaN                 NaN       NaN  \n",
       "25%       NaN                 NaN       NaN  \n",
       "50%       NaN                 NaN       NaN  \n",
       "75%       NaN                 NaN       NaN  \n",
       "max       NaN                 NaN       NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A method for Finding Unique items for all columns\n",
    "def unique_items(list1, list2):\n",
    "  a = list1\n",
    "  b = list2\n",
    "  a.extend(b)\n",
    "  return list(set(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_Title = LabelEncoder()\n",
    "all_titles = unique_items(list(X_train.Title),list(X_test.Title))\n",
    "le_Title.fit(all_titles)\n",
    "\n",
    "le_Edition_Type = LabelEncoder()\n",
    "all_etypes = unique_items(list(X_train.Edition_Type),list(X_test.Edition_Type))\n",
    "le_Edition_Type.fit(all_etypes)\n",
    "\n",
    "\n",
    "le_Edition_Month = LabelEncoder()\n",
    "all_em = unique_items(list(X_train.Edition_Month),list(X_test.Edition_Month))\n",
    "le_Edition_Month.fit(all_em)\n",
    "\n",
    "le_Author = LabelEncoder()\n",
    "all_Authors = list(set(all_authors))\n",
    "le_Author.fit(all_Authors)\n",
    "\n",
    "le_Genre = LabelEncoder()\n",
    "all_Genres = list(set(all_genres))\n",
    "le_Genre.fit(all_Genres)\n",
    "\n",
    "le_Category = LabelEncoder()\n",
    "all_Categories = list(set(all_categories))\n",
    "le_Category.fit(all_Categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Title'] = le_Title.transform(X_train['Title'])\n",
    "\n",
    "X_train['Edition_Type'] = le_Edition_Type.transform(X_train['Edition_Type'])\n",
    "\n",
    "\n",
    "\n",
    "X_train['Edition_Month'] = le_Edition_Month.transform(X_train['Edition_Month'])\n",
    "\n",
    "X_train['Author1'] = le_Author.transform(X_train['Author1'])\n",
    "X_train['Author2'] = le_Author.transform(X_train['Author2'])\n",
    "X_train['Author3'] = le_Author.transform(X_train['Author3'])\n",
    "X_train['Author4'] = le_Author.transform(X_train['Author4'])\n",
    "X_train['Author5'] = le_Author.transform(X_train['Author5'])\n",
    "X_train['Author6'] = le_Author.transform(X_train['Author6'])\n",
    "X_train['Author7'] = le_Author.transform(X_train['Author7'])\n",
    "\n",
    "\n",
    "X_train['Genre1'] = le_Genre.transform(X_train['Genre1'])\n",
    "X_train['Genre2'] = le_Genre.transform(X_train['Genre2'])\n",
    "\n",
    "\n",
    "X_train['Category1'] = le_Category.transform(X_train['Category1'])\n",
    "X_train['Category2'] = le_Category.transform(X_train['Category2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author1</th>\n",
       "      <th>Author2</th>\n",
       "      <th>Author3</th>\n",
       "      <th>Author4</th>\n",
       "      <th>Author5</th>\n",
       "      <th>Author6</th>\n",
       "      <th>Author7</th>\n",
       "      <th>Edition_Type</th>\n",
       "      <th>Edition_Month</th>\n",
       "      <th>Edition_Year</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Genre1</th>\n",
       "      <th>Genre2</th>\n",
       "      <th>Category1</th>\n",
       "      <th>Category2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5802</td>\n",
       "      <td>797</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2120</td>\n",
       "      <td>391</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>3.9</td>\n",
       "      <td>14</td>\n",
       "      <td>80</td>\n",
       "      <td>267</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2984</td>\n",
       "      <td>4353</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1982</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6</td>\n",
       "      <td>211</td>\n",
       "      <td>267</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>189</td>\n",
       "      <td>78</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>4.1</td>\n",
       "      <td>13</td>\n",
       "      <td>98</td>\n",
       "      <td>267</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987</td>\n",
       "      <td>1221</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>3073</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>284</td>\n",
       "      <td>267</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Title  Author1  Author2  Author3  Author4  Author5  Author6  Author7  \\\n",
       "0   5802      797     3073     3073     3073     3073     3073     3073   \n",
       "1   2120      391     3073     3073     3073     3073     3073     3073   \n",
       "2   2984     4353     3073     3073     3073     3073     3073     3073   \n",
       "3    189       78     3073     3073     3073     3073     3073     3073   \n",
       "4   2987     1221     3073     3073     3073     3073     3073     3073   \n",
       "\n",
       "   Edition_Type  Edition_Month  Edition_Year  Ratings  Reviews  Genre1  \\\n",
       "0            13              7          2016      4.0        8       0   \n",
       "1            13             10          2012      3.9       14      80   \n",
       "2            13              3          1982      4.8        6     211   \n",
       "3            13             11          2017      4.1       13      98   \n",
       "4             8             11          2006      5.0        1     284   \n",
       "\n",
       "   Genre2  Category1  Category2  \n",
       "0     267          0         12  \n",
       "1     267          2          6  \n",
       "2     267          8         12  \n",
       "3     267          5         16  \n",
       "4     267          1          7  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Title'] = le_Title.transform(X_test['Title'])\n",
    "\n",
    "X_test['Edition_Type'] = le_Edition_Type.transform(X_test['Edition_Type'])\n",
    "\n",
    "\n",
    "\n",
    "X_test['Edition_Month'] = le_Edition_Month.transform(X_test['Edition_Month'])\n",
    "\n",
    "X_test['Author1'] = le_Author.transform(X_test['Author1'])\n",
    "X_test['Author2'] = le_Author.transform(X_test['Author2'])\n",
    "X_test['Author3'] = le_Author.transform(X_test['Author3'])\n",
    "X_test['Author4'] = le_Author.transform(X_test['Author4'])\n",
    "X_test['Author5'] = le_Author.transform(X_test['Author5'])\n",
    "X_test['Author6'] = le_Author.transform(X_test['Author6'])\n",
    "X_test['Author7'] = le_Author.transform(X_test['Author7'])\n",
    "\n",
    "\n",
    "X_test['Genre1'] = le_Genre.transform(X_test['Genre1'])\n",
    "X_test['Genre2'] = le_Genre.transform(X_test['Genre2'])\n",
    "\n",
    "\n",
    "X_test['Category1'] = le_Category.transform(X_test['Category1'])\n",
    "X_test['Category2'] = le_Category.transform(X_test['Category2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#Reshaping ti fit the scaler\n",
    "Y_train = Y_train.reshape((len(Y_train), 1)) \n",
    "\n",
    "Y_train = sc.fit_transform(Y_train)\n",
    "\n",
    "#Restoring the original shape after scaling\n",
    "Y_train = Y_train.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(X_train, Y_train, test_size = 0.1, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5613, 17)\n",
      "(5613,)\n",
      "(624, 17)\n",
      "(624,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(val_x.shape)\n",
    "print(val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMLSE Score =  0.7163958911417463\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "\n",
    "xgb=XGBRegressor( objective='reg:squarederror', max_depth=6, learning_rate=0.1, n_estimators=100, booster = 'gbtree', n_jobs = -1,random_state = 1)\n",
    "xgb.fit(train_x,train_y)\n",
    "\n",
    "y_pred = sc.inverse_transform(xgb.predict(val_x))\n",
    "y_true = sc.inverse_transform(val_y)\n",
    "\n",
    "error = np.square(np.log10(y_pred +1) - np.log10(y_true +1)).mean() ** 0.5\n",
    "score = 1 - error\n",
    "\n",
    "print(\"RMLSE Score = \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=6, min_child_weight=1, missing=None, n_estimators=100,\n",
       "             n_jobs=-1, nthread=None, objective='reg:squarederror',\n",
       "             random_state=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             seed=None, silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the complete training set (inclusing val_x and val_y)\n",
    "xgb.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for test set\n",
    "y_pred_xgb = sc.inverse_transform(xgb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the predictions in excel file\n",
    "\n",
    "solution = pd.DataFrame(y_pred_xgb, columns = ['Price'])\n",
    "solution.to_excel('Predict_Book_Price_Soln.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>214.681122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1330.917114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>624.322449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>844.769043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>425.502533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>890.277893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>956.208252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>339.453979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>558.580017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>467.108673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Price\n",
       "0   214.681122\n",
       "1  1330.917114\n",
       "2   624.322449\n",
       "3   844.769043\n",
       "4   425.502533\n",
       "5   890.277893\n",
       "6   956.208252\n",
       "7   339.453979\n",
       "8   558.580017\n",
       "9   467.108673"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "#from sklearn.metrics import mean_squared_error,mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label= Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bo_tune_xgb(max_depth, gamma, n_estimators ,learning_rate):\n",
    "    params = {'max_depth': int(max_depth),\n",
    "              'gamma': gamma,      \n",
    "              'n_estimators': int(n_estimators),\n",
    "              'learning_rate':learning_rate,\n",
    "              'subsample': 0.8,\n",
    "              'eta': 0.1,\n",
    "              'eval_metric': 'rmse'}\n",
    "    \n",
    "    #Cross validating with the specified parameters in 5 folds and 70 iterations\n",
    "    cv_result = xgb.cv(params, dtrain, num_boost_round=100, nfold=10)    \n",
    "    \n",
    "    #Return the negative RMSE\n",
    "    return -1.0 * cv_result['test-rmse-mean'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   gamma   | learni... | max_depth | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.9142  \u001b[0m | \u001b[0m 0.639   \u001b[0m | \u001b[0m 0.05621 \u001b[0m | \u001b[0m 213.3   \u001b[0m | \u001b[0m 288.7   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.9526  \u001b[0m | \u001b[0m 0.3156  \u001b[0m | \u001b[0m 0.2679  \u001b[0m | \u001b[0m 62.85   \u001b[0m | \u001b[0m 364.7   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.9478  \u001b[0m | \u001b[0m 0.8007  \u001b[0m | \u001b[0m 0.25    \u001b[0m | \u001b[0m 299.9   \u001b[0m | \u001b[0m 165.0   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-1.033   \u001b[0m | \u001b[0m 0.2881  \u001b[0m | \u001b[0m 0.6308  \u001b[0m | \u001b[0m 157.8   \u001b[0m | \u001b[0m 988.8   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.9328  \u001b[0m | \u001b[0m 0.1779  \u001b[0m | \u001b[0m 0.1263  \u001b[0m | \u001b[0m 238.9   \u001b[0m | \u001b[0m 541.4   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.9714  \u001b[0m | \u001b[0m 0.6908  \u001b[0m | \u001b[0m 0.3956  \u001b[0m | \u001b[0m 245.2   \u001b[0m | \u001b[0m 170.7   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.9162  \u001b[0m | \u001b[0m 0.6545  \u001b[0m | \u001b[0m 0.07038 \u001b[0m | \u001b[0m 126.7   \u001b[0m | \u001b[0m 744.9   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-1.131   \u001b[0m | \u001b[0m 0.2472  \u001b[0m | \u001b[0m 0.9876  \u001b[0m | \u001b[0m 163.6   \u001b[0m | \u001b[0m 175.4   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.9954  \u001b[0m | \u001b[0m 0.05716 \u001b[0m | \u001b[0m 0.4762  \u001b[0m | \u001b[0m 254.4   \u001b[0m | \u001b[0m 660.1   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.9874  \u001b[0m | \u001b[0m 0.32    \u001b[0m | \u001b[0m 0.4075  \u001b[0m | \u001b[0m 233.9   \u001b[0m | \u001b[0m 550.1   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-1.112   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 300.0   \u001b[0m | \u001b[0m 444.4   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-1.112   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 300.0   \u001b[0m | \u001b[0m 837.5   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-1.112   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 876.1   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-1.112   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 300.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-1.112   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-1.112   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 174.6   \u001b[0m | \u001b[0m 423.3   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-1.112   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 300.0   \u001b[0m | \u001b[0m 551.5   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-1.112   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 269.5   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-1.112   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 502.4   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-1.112   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 205.1   \u001b[0m | \u001b[0m 772.2   \u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "xgb_bo = BayesianOptimization(bo_tune_xgb, {'max_depth': (1, 300), \n",
    "                                             'gamma': (0, 1),\n",
    "                                             'learning_rate':(0,1),\n",
    "                                             'n_estimators':(1,1000)\n",
    "                                            })\n",
    "\n",
    "\n",
    "xgb_bo.maximize(n_iter=10, init_points=10, acq='ei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.6390330288507643, 'learning_rate': 0.05621187512068493, 'max_depth': 213.31687475054977, 'n_estimators': 288.68764832032974}\n",
      "{'gamma': 0.6390330288507643, 'learning_rate': 0.05621187512068493, 'max_depth': 213, 'n_estimators': 289}\n"
     ]
    }
   ],
   "source": [
    "#Extracting the best parameters\n",
    "params = xgb_bo.max['params']\n",
    "\n",
    "print(params)\n",
    "\n",
    "#Conversting the max_depth and n_estimator values from float to int\n",
    "params['max_depth']= int(round(params['max_depth']))\n",
    "params['n_estimators']= int(round(params['n_estimators']))\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:53:03] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "#Initialize an XGB with the tuned parameters and fit the training data\n",
    "from xgboost import XGBRegressor\n",
    "reg = XGBRegressor(**params).fit(X_train,Y_train)\n",
    "\n",
    "y_pred_reg = sc.inverse_transform(reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237.709229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1686.145020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>389.132660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>959.598450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>347.959076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>517.618774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>695.759460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>346.432739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>450.300537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>395.979858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Price\n",
       "0   237.709229\n",
       "1  1686.145020\n",
       "2   389.132660\n",
       "3   959.598450\n",
       "4   347.959076\n",
       "5   517.618774\n",
       "6   695.759460\n",
       "7   346.432739\n",
       "8   450.300537\n",
       "9   395.979858"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution_bo = pd.DataFrame(y_pred_reg, columns = ['Price'])\n",
    "\n",
    "solution_bo.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_bo.to_excel('Predict_Book_Prices_BO_Soln.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
